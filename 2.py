# -*- coding: utf-8 -*-
"""Untitled5.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1zv0J6vM4GdmrTDNtezcjpBGnXuvh43Wb
"""

import streamlit as st
import os
import google.generativeai as genai
from langchain_google_genai import GoogleGenerativeAIEmbeddings, ChatGoogleGenerativeAI
from langchain_community.document_loaders import PyPDFLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_community.vectorstores import Chroma
from langchain_core.prompts import PromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnablePassthrough

# --- 1. API í‚¤ ì„¤ì • ë° ë°ì´í„°ë² ì´ìŠ¤ ì¤€ë¹„ ---

# ChromaDB ì €ì¥ ê²½ë¡œ
DB_DIR = "./chroma_db"

# Streamlit Secretsì—ì„œ API í‚¤ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.
try:
    GOOGLE_API_KEY = st.secrets["GOOGLE_API_KEY"]
    genai.configure(api_key=GOOGLE_API_KEY)
except (KeyError, FileNotFoundError):
    st.error("ì˜¤ë¥˜: Gemini API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    st.info("Streamlit ì•±ì˜ 'Settings > Secrets'ì—ì„œ GOOGLE_API_KEYë¥¼ ì¶”ê°€í•´ì£¼ì„¸ìš”.")
    st.stop()


def setup_database():
    """
    ChromaDBê°€ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸í•˜ê³ , ì—†ìœ¼ë©´ ìƒˆë¡œ ìƒì„±í•˜ëŠ” í•¨ìˆ˜.
    Streamlit Cloudì˜ ì„ì‹œ ì €ì¥ì†Œì— DBë¥¼ êµ¬ì¶•í•©ë‹ˆë‹¤.
    """
    if os.path.exists(DB_DIR):
        st.sidebar.info("ê¸°ì¡´ ë°ì´í„°ë² ì´ìŠ¤ë¥¼ ë¡œë“œí–ˆìŠµë‹ˆë‹¤.")
        return

    st.sidebar.info("ìƒˆë¡œìš´ ë°ì´í„°ë² ì´ìŠ¤ë¥¼ êµ¬ì¶•í•˜ê³  ìˆìŠµë‹ˆë‹¤. ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”...")

    # 1. ë¬¸ì„œ ë¡œë“œ
    docs = []
    data_path = "./data"
    pdf_files = [f for f in os.listdir(data_path) if f.endswith('.pdf')]
    if not pdf_files:
        st.error("ì˜¤ë¥˜: data í´ë”ì— PDF íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        st.stop()

    for pdf_file in pdf_files:
        loader = PyPDFLoader(os.path.join(data_path, pdf_file))
        docs.extend(loader.load())

    # 2. í…ìŠ¤íŠ¸ ë¶„í• 
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)
    splits = text_splitter.split_documents(docs)

    # 3. ì„ë² ë”© ë° ChromaDB ì €ì¥
    try:
        embeddings = GoogleGenerativeAIEmbeddings(model="models/embedding-001")
        Chroma.from_documents(
            documents=splits,
            embedding=embeddings,
            persist_directory=DB_DIR
        )
        st.sidebar.success("ë°ì´í„°ë² ì´ìŠ¤ êµ¬ì¶•ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
    except Exception as e:
        st.error(f"ë°ì´í„°ë² ì´ìŠ¤ êµ¬ì¶• ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
        st.stop()

@st.cache_resource
def get_rag_chain():
    """
    RAG ì²´ì¸ì„ ì´ˆê¸°í™”í•˜ê³  ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜.
    Streamlitì˜ ìºì‹±ì„ ì‚¬ìš©í•˜ì—¬ ë¦¬ì†ŒìŠ¤ë¥¼ íš¨ìœ¨ì ìœ¼ë¡œ ê´€ë¦¬í•©ë‹ˆë‹¤.
    """
    try:
        embeddings = GoogleGenerativeAIEmbeddings(model="models/embedding-001")

        vector_store = Chroma(
            persist_directory=DB_DIR,
            embedding_function=embeddings
        )
        retriever = vector_store.as_retriever()

        llm = ChatGoogleGenerativeAI(model="gemini-1.5-flash", temperature=0)

        template = """ë‹¹ì‹ ì€ ëŒ€í•œë¯¼êµ­ ì •ë¶€ ì •ì±… ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ëŒ€í•´ ì•„ë˜ì˜ 'ë¬¸ì„œ ë‚´ìš©'ì„ ë°”íƒ•ìœ¼ë¡œ, ëª…í™•í•˜ê³  ì¹œì ˆí•˜ê²Œ ë‹µë³€í•´ì£¼ì„¸ìš”.
        ë¬¸ì„œ ë‚´ìš©ì— ì—†ëŠ” ì •ë³´ëŠ” ë‹µë³€ì— í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”. ë‹µë³€ì€ í•­ìƒ í•œêµ­ì–´ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.

        [ë¬¸ì„œ ë‚´ìš©]
        {context}

        [ì‚¬ìš©ì ì§ˆë¬¸]
        {question}

        [ë‹µë³€]
        """

        prompt = PromptTemplate.from_template(template)

        rag_chain = (
            {"context": retriever, "question": RunnablePassthrough()}
            | prompt
            | llm
            | StrOutputParser()
        )

        return rag_chain, retriever
    except Exception as e:
        st.error(f"RAG íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ì˜¤ë¥˜: {e}")
        st.stop()

# --- 2. Streamlit UI êµ¬ì„± ---

st.set_page_config(page_title="ì •ì±… íë ˆì´í„° (Gemini)", page_icon="ğŸ¤–")
st.title("ğŸ¤– ì •ì±… íë ˆì´í„° (Gemini Ver.)")
st.caption("AIê°€ ì •ë¶€ ì •ì±… ë¬¸ì„œë¥¼ ë¶„ì„í•˜ì—¬ ì§ˆë¬¸ì— ë‹µë³€í•´ ë“œë¦½ë‹ˆë‹¤.")

with st.sidebar:
    st.header("ì•ˆë‚´")
    st.markdown("""
    ì´ ì•±ì€ Google Gemini APIì™€ RAG ê¸°ìˆ ì„ ì‚¬ìš©í•˜ì—¬ PDF ë¬¸ì„œì˜ ë‚´ìš©ì„ ê¸°ë°˜ìœ¼ë¡œ ì§ˆë¬¸ì— ë‹µë³€í•©ë‹ˆë‹¤.

    **ë°°í¬ ì•ˆë‚´:**
    1. ì´ í”„ë¡œì íŠ¸ë¥¼ GitHubì— ì—…ë¡œë“œí•˜ì„¸ìš”.
    2. Streamlit Cloudì— ë¡œê·¸ì¸í•˜ì—¬ ìƒˆ ì•±ì„ ë§Œë“­ë‹ˆë‹¤.
    3. GitHub ë¦¬í¬ì§€í† ë¦¬ë¥¼ ì—°ê²°í•©ë‹ˆë‹¤.
    4. **Advanced settings...** ì—ì„œ `GOOGLE_API_KEY`ë¥¼ Secretsì— ì¶”ê°€í•©ë‹ˆë‹¤.
       - í˜•ì‹: `GOOGLE_API_KEY = "AIzaSy..."`
    5. **Deploy!** ë²„íŠ¼ì„ ëˆ„ë¥´ë©´ ë°°í¬ê°€ ì‹œì‘ë©ë‹ˆë‹¤.
    """)

# ë°ì´í„°ë² ì´ìŠ¤ ì„¤ì • ì‹¤í–‰
setup_database()

# RAG ì²´ì¸ê³¼ retriever ë¡œë“œ
rag_chain, retriever = get_rag_chain()

# ì„¸ì…˜ ìƒíƒœë¥¼ ì‚¬ìš©í•˜ì—¬ ëŒ€í™” ê¸°ë¡ ì €ì¥
if "messages" not in st.session_state:
    st.session_state.messages = []

# ì´ì „ ëŒ€í™” ê¸°ë¡ í‘œì‹œ
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])
        if "sources" in message and message["sources"]:
            with st.expander("ğŸ“š ê·¼ê±° ìë£Œ í™•ì¸í•˜ê¸°"):
                for i, source in enumerate(message["sources"]):
                    st.markdown(f"**ë¬¸ì„œ {i+1} (ì¶œì²˜: {source.metadata.get('source', 'N/A')}, í˜ì´ì§€: {source.metadata.get('page', 'N/A')})**")
                    st.markdown(f"> {source.page_content}")
                    st.markdown("---")

# ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬
if prompt := st.chat_input("ê¶ê¸ˆí•œ ì •ì±…ì— ëŒ€í•´ ì§ˆë¬¸í•´ë³´ì„¸ìš”."):
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    with st.spinner("ë‹µë³€ì„ ìƒì„±í•˜ëŠ” ì¤‘ì…ë‹ˆë‹¤..."):
        try:
            answer = rag_chain.invoke(prompt)
            sources = retriever.invoke(prompt)
            bot_message = {"role": "assistant", "content": answer, "sources": sources}
            st.session_state.messages.append(bot_message)
            st.rerun()
        except Exception as e:
            st.error(f"ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")