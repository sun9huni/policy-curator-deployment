# -*- coding: utf-8 -*-
"""Untitled4.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1lip1hlxbZSkbBUycIRkLGtHBN5sF7U93
"""

import streamlit as st
import os
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from langchain_community.document_loaders import PyPDFLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_community.vectorstores import Chroma
from langchain_core.prompts import PromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnablePassthrough

# --- 1. ë°ì´í„°ë² ì´ìŠ¤ ì¤€ë¹„ ë° RAG íŒŒì´í”„ë¼ì¸ ì„¤ì • ---

# ChromaDB ì €ì¥ ê²½ë¡œ
DB_DIR = "./chroma_db"

def setup_database():
    """
    ChromaDBê°€ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸í•˜ê³ , ì—†ìœ¼ë©´ ìƒˆë¡œ ìƒì„±í•˜ëŠ” í•¨ìˆ˜.
    Streamlit Cloudì˜ ì„ì‹œ ì €ì¥ì†Œì— DBë¥¼ êµ¬ì¶•í•©ë‹ˆë‹¤.
    """
    if os.path.exists(DB_DIR):
        st.sidebar.info("ê¸°ì¡´ ë°ì´í„°ë² ì´ìŠ¤ë¥¼ ë¡œë“œí–ˆìŠµë‹ˆë‹¤.")
        return

    st.sidebar.info("ìƒˆë¡œìš´ ë°ì´í„°ë² ì´ìŠ¤ë¥¼ êµ¬ì¶•í•˜ê³  ìˆìŠµë‹ˆë‹¤. ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”...")

    # 1. ë¬¸ì„œ ë¡œë“œ
    docs = []
    data_path = "./data"
    pdf_files = [f for f in os.listdir(data_path) if f.endswith('.pdf')]
    if not pdf_files:
        st.error("ì˜¤ë¥˜: data í´ë”ì— PDF íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        st.stop()

    for pdf_file in pdf_files:
        loader = PyPDFLoader(os.path.join(data_path, pdf_file))
        docs.extend(loader.load())

    # 2. í…ìŠ¤íŠ¸ ë¶„í• 
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)
    splits = text_splitter.split_documents(docs)

    # 3. ì„ë² ë”© ë° ChromaDB ì €ì¥
    try:
        # OpenAI API í‚¤ëŠ” Streamlit Secretsì—ì„œ ìë™ìœ¼ë¡œ ë¡œë“œë©ë‹ˆë‹¤.
        embeddings = OpenAIEmbeddings()
        Chroma.from_documents(
            documents=splits,
            embedding=embeddings,
            persist_directory=DB_DIR
        )
        st.sidebar.success("ë°ì´í„°ë² ì´ìŠ¤ êµ¬ì¶•ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
    except Exception as e:
        st.error(f"ë°ì´í„°ë² ì´ìŠ¤ êµ¬ì¶• ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
        st.stop()

@st.cache_resource
def get_rag_chain():
    """
    RAG ì²´ì¸ì„ ì´ˆê¸°í™”í•˜ê³  ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜.
    Streamlitì˜ ìºì‹±ì„ ì‚¬ìš©í•˜ì—¬ ë¦¬ì†ŒìŠ¤ë¥¼ íš¨ìœ¨ì ìœ¼ë¡œ ê´€ë¦¬í•©ë‹ˆë‹¤.
    """
    try:
        # OpenAI API í‚¤ëŠ” Streamlit Secretsì—ì„œ ìë™ìœ¼ë¡œ ë¡œë“œë©ë‹ˆë‹¤.
        embeddings = OpenAIEmbeddings()

        # ë””ìŠ¤í¬ì— ì €ì¥ëœ ChromaDBë¥¼ ë¡œë“œ
        vector_store = Chroma(
            persist_directory=DB_DIR,
            embedding_function=embeddings
        )
        retriever = vector_store.as_retriever()

        # ì–¸ì–´ ëª¨ë¸(LLM) ì´ˆê¸°í™”
        llm = ChatOpenAI(model="gpt-4o", temperature=0)

        # í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì •ì˜
        template = """ë‹¹ì‹ ì€ ëŒ€í•œë¯¼êµ­ ì •ë¶€ ì •ì±… ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ëŒ€í•´ ì•„ë˜ì˜ 'ë¬¸ì„œ ë‚´ìš©'ì„ ë°”íƒ•ìœ¼ë¡œ, ëª…í™•í•˜ê³  ì¹œì ˆí•˜ê²Œ ë‹µë³€í•´ì£¼ì„¸ìš”.
        ë¬¸ì„œ ë‚´ìš©ì— ì—†ëŠ” ì •ë³´ëŠ” ë‹µë³€ì— í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”. ë‹µë³€ì€ í•­ìƒ í•œêµ­ì–´ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.

        [ë¬¸ì„œ ë‚´ìš©]
        {context}

        [ì‚¬ìš©ì ì§ˆë¬¸]
        {question}

        [ë‹µë³€]
        """

        prompt = PromptTemplate.from_template(template)

        # RAG ì²´ì¸ êµ¬ì„±
        rag_chain = (
            {"context": retriever, "question": RunnablePassthrough()}
            | prompt
            | llm
            | StrOutputParser()
        )

        return rag_chain, retriever
    except Exception as e:
        st.error(f"RAG íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. OpenAI API í‚¤ê°€ ì˜¬ë°”ë¥´ê²Œ ì„¤ì •ë˜ì—ˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”. ì˜¤ë¥˜: {e}")
        st.stop()

# --- 2. Streamlit UI êµ¬ì„± ---

st.set_page_config(page_title="ì •ì±… íë ˆì´í„°", page_icon="ğŸ¤–")
st.title("ğŸ¤– ì •ì±… íë ˆì´í„°")
st.caption("AIê°€ ì •ë¶€ ì •ì±… ë¬¸ì„œë¥¼ ë¶„ì„í•˜ì—¬ ì§ˆë¬¸ì— ë‹µë³€í•´ ë“œë¦½ë‹ˆë‹¤.")

with st.sidebar:
    st.header("ì•ˆë‚´")
    st.markdown("""
    ì´ ì•±ì€ RAG(ê²€ìƒ‰ ì¦ê°• ìƒì„±) ê¸°ìˆ ì„ ì‚¬ìš©í•˜ì—¬ PDF ë¬¸ì„œì˜ ë‚´ìš©ì„ ê¸°ë°˜ìœ¼ë¡œ ì§ˆë¬¸ì— ë‹µë³€í•©ë‹ˆë‹¤.

    **ë°°í¬ ì•ˆë‚´:**
    1. ì´ í”„ë¡œì íŠ¸ë¥¼ GitHubì— ì—…ë¡œë“œí•˜ì„¸ìš”.
    2. Streamlit Cloudì— ë¡œê·¸ì¸í•˜ì—¬ ìƒˆ ì•±ì„ ë§Œë“­ë‹ˆë‹¤.
    3. GitHub ë¦¬í¬ì§€í† ë¦¬ë¥¼ ì—°ê²°í•©ë‹ˆë‹¤.
    4. **Advanced settings...** ì—ì„œ `OPENAI_API_KEY`ë¥¼ Secretsì— ì¶”ê°€í•©ë‹ˆë‹¤.
       - í˜•ì‹: `OPENAI_API_KEY = "sk-..."`
    5. **Deploy!** ë²„íŠ¼ì„ ëˆ„ë¥´ë©´ ë°°í¬ê°€ ì‹œì‘ë©ë‹ˆë‹¤.

    ì²« ë°°í¬ ì‹œì—ëŠ” PDFë¥¼ ì²˜ë¦¬í•˜ì—¬ ë°ì´í„°ë² ì´ìŠ¤ë¥¼ êµ¬ì¶•í•˜ë¯€ë¡œ ì‹œê°„ì´ ë‹¤ì†Œ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    """)

# ë°ì´í„°ë² ì´ìŠ¤ ì„¤ì • ì‹¤í–‰
setup_database()

# RAG ì²´ì¸ê³¼ retriever ë¡œë“œ
rag_chain, retriever = get_rag_chain()

# ì„¸ì…˜ ìƒíƒœë¥¼ ì‚¬ìš©í•˜ì—¬ ëŒ€í™” ê¸°ë¡ ì €ì¥
if "messages" not in st.session_state:
    st.session_state.messages = []

# ì´ì „ ëŒ€í™” ê¸°ë¡ í‘œì‹œ
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])
        # ê·¼ê±° ìë£Œê°€ ìˆëŠ” ê²½ìš°, í™•ì¥ ê°€ëŠ¥í•œ í˜•íƒœë¡œ í‘œì‹œ
        if "sources" in message and message["sources"]:
            with st.expander("ğŸ“š ê·¼ê±° ìë£Œ í™•ì¸í•˜ê¸°"):
                for i, source in enumerate(message["sources"]):
                    st.markdown(f"**ë¬¸ì„œ {i+1} (ì¶œì²˜: {source.metadata.get('source', 'N/A')}, í˜ì´ì§€: {source.metadata.get('page', 'N/A')})**")
                    st.markdown(f"> {source.page_content}")
                    st.markdown("---")

# ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬
if prompt := st.chat_input("ê¶ê¸ˆí•œ ì •ì±…ì— ëŒ€í•´ ì§ˆë¬¸í•´ë³´ì„¸ìš”."):
    # ì‚¬ìš©ì ë©”ì‹œì§€ë¥¼ ëŒ€í™” ê¸°ë¡ì— ì¶”ê°€í•˜ê³  í™”ë©´ì— í‘œì‹œ
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    # ë¡œë”© ìŠ¤í”¼ë„ˆ í‘œì‹œ
    with st.spinner("ë‹µë³€ì„ ìƒì„±í•˜ëŠ” ì¤‘ì…ë‹ˆë‹¤..."):
        try:
            # RAG ì²´ì¸ì„ ì§ì ‘ í˜¸ì¶œí•˜ì—¬ ë‹µë³€ ìƒì„±
            answer = rag_chain.invoke(prompt)

            # ë‹µë³€ì˜ ê·¼ê±°ê°€ ëœ ë¬¸ì„œ ê²€ìƒ‰
            sources = retriever.invoke(prompt)

            # AI ì‘ë‹µì„ ëŒ€í™” ê¸°ë¡ì— ì¶”ê°€í•˜ê³  í™”ë©´ì— í‘œì‹œ
            bot_message = {"role": "assistant", "content": answer, "sources": sources}
            st.session_state.messages.append(bot_message)

            # Streamlitì´ ë©”ì‹œì§€ë¥¼ ë‹¤ì‹œ ê·¸ë¦¬ë„ë¡ ê°•ì œ
            st.rerun()

        except Exception as e:
            st.error(f"ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")